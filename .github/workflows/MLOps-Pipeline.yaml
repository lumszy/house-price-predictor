name: MLOps Pipeline

on:
  workflow_dispatch:
    inputs:
      run_all:
        description: 'Run all jobs'
        required: false
        default: 'true'
      run_data_processing:
        description: 'Run data Processing jobs'
        required: false
        default: false
      run_model_training:
        description: 'Run model training jobs'
        required: false
        default: false
      run_build_and_publish:
        description: 'Run build and publish jobs'
        required: false
        default: false
  release:
    types: [created]
    branches: [main]
    tags: [ 'v*.*.*']

jobs:
  data-processing:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.11.9'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Process data
      run: |
        python src/data/run_processing.py --input data/raw/house_data.csv --output data/processed/cleaned_house_data.csv
    - name: Engineer Feature
      run: |
        python src/features/engineer.py --input data/processed/cleaned_house_data.csv --output data/processed/featured_house_data.csv --preprocessor models/trained/preprocessor.pkl
    - name: Upload processed data
      uses: actions/upload-artifact@v4
      with:
        name: processed data
        path: data/processed/featured_house_data.csv
    - name: Upload preprocessor
      uses: actions/upload-artifact@v4
      with:
        name: preprocessor
        path: models/trained/preprocessor.pkl

  model-training:
    runs-on: ubuntu-latest
    needs: data-processing
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.11.9'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Download processed data
      uses: actions/download-artifact@v4
      with:
        name: processed data
        path: data/processed/
    - name: Set up MLflow
      run: |
        docker pull ghcr.io/mlflow/mlflow:latest
        docker run -d -p 0.0.0.0:5555:5000 --name mlflow-server ghcr.io/mlflow/mlflow:latest mlflow server --host 0.0.0.0 --backend-store-uri sqlite:///mlflow.db --default-artifact-root /tmp/mlruns
    - name: Wait for MLflow to start
      run: |
        for i in {1..10}; do
        #   curl -f http://localhost:5555/health || sleep 5:
        # done
          if curl -s http://localhost:5555 >/dev/null; then
            echo "MLflow server is up"
            break
          else
            echo "Waiting for MLflow server..."
            sleep 5
          fi
        done
    - name: Train model
      run: |
        python src/models/train_model.py \
          --config configs/model_config.yaml \
          --data data/processed/featured_house_data.csv \
          --models-dir models \
          --mlflow-tracking-uri http://localhost:5555
    - name: Upload trained model
      uses: actions/upload-artifact@v4
      with:
        name: trained-model
        path: models/
    
    - name: Clean up MLflow
      run: |
        docker stop mlflow-server || true
        docker rm mlflow-server || true
  
  build-and-publish:
    needs: model-training
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Download trained model
      uses: actions/download-artifact@v4
      with:
        name: trained-model
        path: models/
    - name: Download preprocessor
      uses: actions/download-artifact@v4
      with:
        name: preprocessor
        path: models/trained/
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build and test Docker image
      run: |
        COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-7)
        docker build -t docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:${COMMIT_HASH} -f Dockerfile .
        docker run -d -p 8000:8000 --name test-api docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:${COMMIT_HASH}
        for i in {1..10}; do
          curl -f http://localhost:8000/health && break || sleep 5;
        done
        docker logs test-api
    - name: CleanUp test container
      run: |
        docker stop test-api || true
        docker rm test-api || true  

    - name: Login to DockerHub
      uses: docker/login-action@v2
      with:
        username: ${{ vars.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}

    - name: Push docker image to DockerHub
      run: |
        COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-7)
        docker tag docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:${COMMIT_HASH} docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest
        docker push docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:${COMMIT_HASH}
        docker push docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest
